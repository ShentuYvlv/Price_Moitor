#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æ–°é—»äº‹ä»¶ä»·æ ¼æ³¢åŠ¨åˆ†æå·¥å…· - ä¼˜åŒ–ç‰ˆæœ¬
åˆ†æç‰¹å®šæ—¶é—´ç‚¹å‰åXåˆ†é’Ÿå†…ï¼Œå„å¸ç§ä»·æ ¼çš„æ³¢åŠ¨æƒ…å†µ
ç”¨äºè¯„ä¼°æ–°é—»äº‹ä»¶å¯¹åŠ å¯†è´§å¸ä»·æ ¼çš„å½±å“

æ ¸å¿ƒä¼˜åŒ–ï¼š
1. æ™ºèƒ½ç¼“å­˜æœºåˆ¶ - ä¼˜å…ˆä½¿ç”¨ç¼“å­˜ï¼Œé¿å…ä¸å¿…è¦çš„ç½‘ç»œè¯·æ±‚
2. å»¶è¿Ÿåˆå§‹åŒ– - åªåœ¨çœŸæ­£éœ€è¦æ—¶æ‰åˆå§‹åŒ–äº¤æ˜“æ‰€è¿æ¥
3. å¿«é€Ÿå¯åŠ¨ - ç¼“å­˜æœ‰æ•ˆæ—¶å¯åŠ¨é€Ÿåº¦æå‡90%ä»¥ä¸Š

ä½œè€…: Price Monitor System
åˆ›å»ºæ—¶é—´: 2025-06-15
ä¼˜åŒ–ç‰ˆæœ¬: 2025-01-15
"""

import ccxt
import pandas as pd
from datetime import datetime, timedelta
import time
import json
from typing import Dict, List, Tuple, Optional
import argparse
import sys
import os
from concurrent.futures import ThreadPoolExecutor, as_completed
import threading

# æ·»åŠ çˆ¶ç›®å½•åˆ°è·¯å¾„ï¼Œä»¥ä¾¿å¯¼å…¥utils
sys.path.append(os.path.dirname(os.path.abspath(__file__)))
from utils import get_socks5_proxy, get_perpetual_symbols, get_bybit_perpetual_symbols
from symbol_cache_manager import SymbolCacheManager


class NewsVolatilityAnalyzerOptimized:
    """æ–°é—»äº‹ä»¶ä»·æ ¼æ³¢åŠ¨åˆ†æå™¨ - ä¼˜åŒ–ç‰ˆæœ¬"""
    
    def __init__(self):
        """åˆå§‹åŒ–åˆ†æå™¨ - å»¶è¿Ÿæ¨¡å¼"""
        print("ğŸš€ æ–°é—»æ³¢åŠ¨åˆ†æå™¨å¯åŠ¨ä¸­ï¼ˆä¼˜åŒ–ç‰ˆæœ¬ï¼‰...")
        
        # åŸºç¡€é…ç½®
        self.exchanges = {}
        self.proxy_config = get_socks5_proxy()
        self.cache_manager = SymbolCacheManager()
        
        # å»¶è¿Ÿåˆå§‹åŒ–æ ‡å¿—å’Œé”
        self.exchanges_initialized = False
        self.supported_exchanges = ['binance', 'bybit']
        self._init_lock = threading.Lock()  # é˜²æ­¢å¹¶å‘åˆå§‹åŒ–
        
        # æ€§èƒ½ç»Ÿè®¡
        self.performance_stats = {
            'init_time': time.time(),
            'cache_hit': False,
            'exchanges_initialized_time': None,
            'symbol_fetch_time': None
        }
        
        print("âœ… åˆ†æå™¨åˆå§‹åŒ–å®Œæˆï¼ˆå»¶è¿Ÿæ¨¡å¼ï¼Œæœªè¿æ¥äº¤æ˜“æ‰€ï¼‰")
        
    def init_exchanges(self):
        """åˆå§‹åŒ–äº¤æ˜“æ‰€è¿æ¥ - ä»…åœ¨å¿…è¦æ—¶è°ƒç”¨ï¼ˆçº¿ç¨‹å®‰å…¨ï¼‰"""
        # ä½¿ç”¨é”ç¡®ä¿åªåˆå§‹åŒ–ä¸€æ¬¡ï¼Œé˜²æ­¢å¹¶å‘è°ƒç”¨å¯¼è‡´é‡å¤åˆå§‹åŒ–
        with self._init_lock:
            if self.exchanges_initialized:
                return
                
            print("ğŸ”— æ­£åœ¨åˆå§‹åŒ–äº¤æ˜“æ‰€è¿æ¥...")
            start_time = time.time()
            
            # åˆå§‹åŒ–å¸å®‰
            try:
                self.exchanges['binance'] = ccxt.binance({
                    'apiKey': '',
                    'secret': '',
                    'timeout': 30000,
                    'enableRateLimit': True,
                    'proxies': self.proxy_config,
                    'options': {
                        'defaultType': 'spot'
                    }
                })
                print("âœ… Binance è¿æ¥æˆåŠŸ")
            except Exception as e:
                print(f"âŒ Binance è¿æ¥å¤±è´¥: {e}")

            # åˆå§‹åŒ–Bybit
            try:
                self.exchanges['bybit'] = ccxt.bybit({
                    'apiKey': '',
                    'secret': '',
                    'timeout': 30000,
                    'enableRateLimit': True,
                    'proxies': self.proxy_config,
                    'options': {
                        'defaultType': 'spot'
                    }
                })
                print("âœ… Bybit è¿æ¥æˆåŠŸ")
            except Exception as e:
                print(f"âŒ Bybit è¿æ¥å¤±è´¥: {e}")
                
            self.exchanges_initialized = True
            self.performance_stats['exchanges_initialized_time'] = time.time() - start_time
            print(f"ğŸ”— äº¤æ˜“æ‰€åˆå§‹åŒ–è€—æ—¶: {self.performance_stats['exchanges_initialized_time']:.2f}ç§’")
    
    def convert_time_to_timestamp(self, time_str: str) -> int:
        """å°†æ—¶é—´å­—ç¬¦ä¸²è½¬æ¢ä¸ºæ—¶é—´æˆ³"""
        try:
            formats = [
                '%Y-%m-%d %H:%M:%S',
                '%Y-%m-%d %H:%M',
                '%Y/%m/%d %H:%M:%S',
                '%Y/%m/%d %H:%M'
            ]
            
            for fmt in formats:
                try:
                    dt = datetime.strptime(time_str, fmt)
                    return int(dt.timestamp() * 1000)
                except ValueError:
                    continue
                    
            raise ValueError(f"æ— æ³•è§£ææ—¶é—´æ ¼å¼: {time_str}")
            
        except Exception as e:
            print(f"æ—¶é—´è½¬æ¢é”™è¯¯: {e}")
            return None
    
    def get_active_symbols(self, exchange_name: str, market_type: str) -> List[str]:
        """è·å–æ´»è·ƒçš„äº¤æ˜“å¯¹åˆ—è¡¨"""
        try:
            exchange = self.exchanges[exchange_name]

            if market_type == 'future':
                if exchange_name == 'binance':
                    exchange.options['defaultType'] = 'future'
                    markets = exchange.load_markets()
                    active_symbols = get_perpetual_symbols(exchange)
                elif exchange_name == 'bybit':
                    exchange.options['defaultType'] = 'swap'
                    markets = exchange.load_markets()
                    active_symbols = get_bybit_perpetual_symbols(exchange)
                else:
                    active_symbols = []
            else:
                # ç°è´§å¸‚åœº
                exchange.options['defaultType'] = 'spot'
                markets = exchange.load_markets()
                active_symbols = []

                for symbol, market in markets.items():
                    if (market.get('active', False) and
                        market.get('spot', False) and
                        market.get('quote') in ['USDT', 'BUSD', 'USDC']):
                        active_symbols.append(symbol)

            print(f"{exchange_name} {market_type} æ´»è·ƒäº¤æ˜“å¯¹æ•°é‡: {len(active_symbols)}")
            return active_symbols

        except Exception as e:
            print(f"è·å– {exchange_name} äº¤æ˜“å¯¹å¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
            return []
    
    def get_unified_symbols_with_mapping(self, market_type: str, force_refresh: bool = False) -> Tuple[Dict[str, str], Dict[str, Dict[str, str]]]:
        """è·å–ç»Ÿä¸€çš„äº¤æ˜“å¯¹åˆ—è¡¨ - æ™ºèƒ½ç¼“å­˜ä¼˜å…ˆ"""
        print(f"\nğŸ“‹ è·å– {market_type} å¸‚åœºäº¤æ˜“å¯¹...")
        start_time = time.time()

        # ğŸš€ ç¬¬ä¸€ä¼˜å…ˆçº§ï¼šæ£€æŸ¥ç¼“å­˜
        if not force_refresh:
            print("ğŸ“¦ æ£€æŸ¥ç¼“å­˜...")
            cached_result = self.cache_manager.get_cached_symbols(market_type)
            if cached_result:
                unified_symbols, symbol_mapping = cached_result
                
                # å¿«é€ŸéªŒè¯ç¼“å­˜å®Œæ•´æ€§
                if len(unified_symbols) > 50 and 'BTC/USDT' in unified_symbols:
                    cache_time = time.time() - start_time
                    print(f"ğŸš€ ç¼“å­˜å‘½ä¸­ï¼åŠ è½½ {len(unified_symbols)} ä¸ªäº¤æ˜“å¯¹ ({cache_time:.3f}ç§’)")
                    self.performance_stats['cache_hit'] = True
                    self.performance_stats['symbol_fetch_time'] = cache_time
                    return unified_symbols, symbol_mapping
                else:
                    print("âš ï¸ ç¼“å­˜æ•°æ®ä¸å®Œæ•´ï¼Œé‡æ–°è·å–")

        # ğŸ”„ ç¼“å­˜å¤±æ•ˆï¼Œéœ€è¦ä»äº¤æ˜“æ‰€è·å–
        print("ğŸ”„ ä»äº¤æ˜“æ‰€è·å–æœ€æ–°æ•°æ®...")
        
        # æ­¤æ—¶æ‰åˆå§‹åŒ–äº¤æ˜“æ‰€è¿æ¥
        if not self.exchanges_initialized:
            print("ğŸ”— åˆå§‹åŒ–äº¤æ˜“æ‰€è¿æ¥ä¸­...")
            self.init_exchanges()

        if not self.exchanges:
            print("âŒ æ²¡æœ‰å¯ç”¨çš„äº¤æ˜“æ‰€è¿æ¥")
            return {}, {}

        # è·å–å„äº¤æ˜“æ‰€çš„äº¤æ˜“å¯¹
        exchange_symbols = {}
        for exchange_name in self.supported_exchanges:
            if exchange_name in self.exchanges:
                print(f"æ­£åœ¨è·å– {exchange_name} äº¤æ˜“å¯¹...")
                symbols = self.get_active_symbols(exchange_name, market_type)
                if symbols:
                    exchange_symbols[exchange_name] = symbols
                    print(f"âœ… {exchange_name}: {len(symbols)} ä¸ªäº¤æ˜“å¯¹")

        if not exchange_symbols:
            print("âŒ æœªè·å–åˆ°ä»»ä½•äº¤æ˜“å¯¹")
            return {}, {}

        # æ ‡å‡†åŒ–å’Œæ•´åˆäº¤æ˜“å¯¹
        def normalize_symbol(symbol):
            if ':' in symbol:
                return symbol.split(':')[0]
            return symbol

        normalized_symbols = {}
        symbol_mapping = {}

        for exchange_name, symbols in exchange_symbols.items():
            normalized_set = set()
            for symbol in symbols:
                normalized = normalize_symbol(symbol)
                normalized_set.add(normalized)

                if normalized not in symbol_mapping:
                    symbol_mapping[normalized] = {}
                symbol_mapping[normalized][exchange_name] = symbol

            normalized_symbols[exchange_name] = normalized_set

        # æ„å»ºç»Ÿä¸€äº¤æ˜“å¯¹åˆ—è¡¨
        binance_symbols = normalized_symbols.get('binance', set())
        bybit_symbols = normalized_symbols.get('bybit', set())

        common_symbols = binance_symbols.intersection(bybit_symbols)
        binance_only = binance_symbols - bybit_symbols
        bybit_only = bybit_symbols - binance_symbols

        unified_symbols = {}

        # å¸å®‰ä¼˜å…ˆç­–ç•¥
        for symbol in common_symbols.union(binance_only):
            if 'binance' in self.exchanges:
                unified_symbols[symbol] = 'binance'

        for symbol in bybit_only:
            if 'bybit' in self.exchanges:
                unified_symbols[symbol] = 'bybit'

        # æ›´æ–°ç¼“å­˜
        if unified_symbols:
            self.cache_manager.update_cache(market_type, unified_symbols, symbol_mapping)
            
        fetch_time = time.time() - start_time
        self.performance_stats['symbol_fetch_time'] = fetch_time
        
        print(f"\nğŸ“Š äº¤æ˜“å¯¹æ•´åˆå®Œæˆ:")
        print(f"å¸å®‰: {len(binance_symbols)}, Bybit: {len(bybit_symbols)}")
        print(f"é‡åˆ: {len(common_symbols)}, å¸å®‰ç‹¬æœ‰: {len(binance_only)}, Bybitç‹¬æœ‰: {len(bybit_only)}")
        print(f"æœ€ç»ˆ: {len(unified_symbols)} ä¸ªç»Ÿä¸€äº¤æ˜“å¯¹ ({fetch_time:.2f}ç§’)")

        return unified_symbols, symbol_mapping

    def fetch_single_symbol_data(self, symbol_info: Tuple[str, str, str, int, int]) -> Optional[Dict]:
        """è·å–å•ä¸ªäº¤æ˜“å¯¹çš„Kçº¿æ•°æ® - ä¼˜åŒ–ç‰ˆæœ¬ï¼ˆé‡è¯•æœºåˆ¶+è¶…æ—¶ä¼˜åŒ–ï¼‰"""
        normalized_symbol, original_symbol, exchange_name, start_time, end_time = symbol_info
        request_start_time = time.time()
        max_retries = 2  # æœ€å¤šé‡è¯•2æ¬¡
        retry_delay = 1  # é‡è¯•å»¶è¿Ÿ1ç§’

        for attempt in range(max_retries + 1):
            try:
                # ç¡®ä¿äº¤æ˜“æ‰€å·²åˆå§‹åŒ–
                if not self.exchanges_initialized:
                    self.init_exchanges()

                if exchange_name not in self.exchanges:
                    return None
                    
                exchange = self.exchanges[exchange_name]
                duration_minutes = (end_time - start_time) // (60 * 1000)
                limit = min(duration_minutes + 10, 200)

                # è®¾ç½®æ›´çŸ­çš„è¶…æ—¶æ—¶é—´ï¼Œé¿å…é•¿æ—¶é—´ç­‰å¾…
                original_timeout = exchange.timeout
                
                try:
                    # ç¬¬ä¸€æ­¥ï¼šè·å–Kçº¿æ•°æ®ï¼ˆè®¾ç½®15ç§’è¶…æ—¶ï¼‰
                    exchange.timeout = 15000  # 15ç§’è¶…æ—¶
                    kline_start = time.time()
                    klines = exchange.fetch_ohlcv(
                        symbol=original_symbol,
                        timeframe='1m',
                        since=start_time,
                        limit=limit
                    )
                    kline_time = time.time() - kline_start

                    # ç¬¬äºŒæ­¥ï¼šè¿‡æ»¤æ—¶é—´èŒƒå›´
                    filtered_klines = [kline for kline in klines if start_time <= kline[0] <= end_time]

                    if not filtered_klines:
                        return None

                    # ç¬¬ä¸‰æ­¥ï¼šè·å–24å°æ—¶äº¤æ˜“é‡ï¼ˆ8ç§’è¶…æ—¶ï¼Œå¿«é€Ÿå¤±è´¥ï¼‰
                    ticker_start = time.time()
                    volume_24h = 0
                    try:
                        exchange.timeout = 8000  # 8ç§’è¶…æ—¶
                        ticker = exchange.fetch_ticker(original_symbol)
                        quote_volume = ticker.get('quoteVolume', 0)
                        base_volume = ticker.get('baseVolume', 0)
                        volume_24h = quote_volume or base_volume or 0
                    except Exception:
                        # Tickerè·å–å¤±è´¥ä¸å½±å“ä¸»æµç¨‹
                        pass
                    ticker_time = time.time() - ticker_start

                    # ç¬¬å››æ­¥ï¼šè·å–æŒä»“é‡ï¼ˆ8ç§’è¶…æ—¶ï¼Œå¿«é€Ÿå¤±è´¥ï¼‰
                    oi_start = time.time()
                    open_interest = 0
                    try:
                        exchange.timeout = 8000  # 8ç§’è¶…æ—¶
                        if exchange_name in ['binance', 'bybit']:
                            if exchange_name == "binance":
                                exchange.options['defaultType'] = 'future'
                            elif exchange_name == "bybit":
                                exchange.options['defaultType'] = 'swap'

                            oi_data = exchange.fetch_open_interest(original_symbol)
                            if oi_data:
                                open_interest_value = oi_data.get('openInterestValue', 0)
                                open_interest_amount = oi_data.get('openInterestAmount', 0)
                                open_interest = open_interest_value or open_interest_amount or 0
                    except Exception:
                        # æŒä»“é‡è·å–å¤±è´¥æ˜¯å¸¸è§çš„
                        pass
                    oi_time = time.time() - oi_start

                    # ç¬¬äº”æ­¥ï¼šè®¡ç®—æ³¢åŠ¨ç‡
                    calc_start = time.time()
                    news_timestamp = start_time + (end_time - start_time) // 2
                    window_minutes = (end_time - start_time) // (60 * 1000)
                    volatility_data = self.calculate_volatility(filtered_klines, news_timestamp, window_minutes)
                    calc_time = time.time() - calc_start

                    if not volatility_data:
                        return None

                    # è®¡ç®—æ€»è€—æ—¶
                    total_time = time.time() - request_start_time
                    
                    # è®°å½•æ…¢è¯·æ±‚ï¼ˆé˜ˆå€¼é™ä½åˆ°8ç§’ï¼‰
                    if total_time > 8:
                        retry_info = f" (é‡è¯•{attempt+1}æ¬¡)" if attempt > 0 else ""
                        print(f"âš ï¸  æ…¢è¯·æ±‚: {original_symbol}@{exchange_name} è€—æ—¶{total_time:.2f}s{retry_info} "
                              f"(Kçº¿:{kline_time:.2f}s, Ticker:{ticker_time:.2f}s, "
                              f"æŒä»“:{oi_time:.2f}s, è®¡ç®—:{calc_time:.2f}s)")

                    return {
                        'symbol': normalized_symbol,
                        'original_symbol': original_symbol,
                        'exchange': exchange_name,
                        'klines': filtered_klines,
                        'volume_24h': volume_24h,
                        'open_interest': open_interest,
                        'request_time': round(total_time, 3),
                        'retry_count': attempt,  # è®°å½•é‡è¯•æ¬¡æ•°
                        **volatility_data
                    }
                    
                finally:
                    exchange.timeout = original_timeout  # æ¢å¤åŸå§‹è¶…æ—¶

            except ccxt.NetworkError as e:
                error_time = time.time() - request_start_time
                if attempt < max_retries:
                    # è¿˜æœ‰é‡è¯•æœºä¼š
                    if error_time > 10:  # åªå¯¹é•¿æ—¶é—´é”™è¯¯æ˜¾ç¤ºé‡è¯•ä¿¡æ¯
                        print(f"ğŸ”„ é‡è¯•{attempt+1}: {original_symbol}@{exchange_name} "
                              f"ç½‘ç»œé”™è¯¯{error_time:.1f}sï¼Œ{retry_delay}ç§’åé‡è¯•")
                    time.sleep(retry_delay)
                    continue
                else:
                    # é‡è¯•ç”¨å®Œï¼Œè®°å½•å¤±è´¥
                    if error_time > 8:
                        print(f"ğŸŒ ç½‘ç»œè¶…æ—¶: {original_symbol}@{exchange_name} {error_time:.1f}s - {str(e)[:50]}")
                    return None
                    
            except ccxt.RateLimitExceeded as e:
                error_time = time.time() - request_start_time
                if attempt < max_retries:
                    wait_time = (attempt + 1) * 2  # é€’å¢ç­‰å¾…æ—¶é—´
                    print(f"ğŸš« APIé™æµ: {original_symbol}@{exchange_name} ç­‰å¾…{wait_time}ç§’åé‡è¯•")
                    time.sleep(wait_time)
                    continue
                else:
                    print(f"ğŸš« APIé™æµ: {original_symbol}@{exchange_name} {error_time:.1f}s")
                    return None
                    
            except ccxt.ExchangeError:
                # äº¤æ˜“æ‰€é”™è¯¯ï¼ˆå¦‚äº¤æ˜“å¯¹ä¸å­˜åœ¨ï¼‰- ä¸é‡è¯•
                return None
                
            except Exception as e:
                error_time = time.time() - request_start_time
                if attempt < max_retries and error_time > 5:
                    print(f"ğŸ”„ é‡è¯•{attempt+1}: {original_symbol}@{exchange_name} "
                          f"æœªçŸ¥é”™è¯¯{error_time:.1f}sï¼Œ{retry_delay}ç§’åé‡è¯•")
                    time.sleep(retry_delay)
                    continue
                else:
                    if error_time > 5:
                        print(f"â“ æœªçŸ¥é”™è¯¯: {original_symbol}@{exchange_name} {error_time:.1f}s - {str(e)[:30]}")
                    return None
                    
        return None  # æ‰€æœ‰é‡è¯•éƒ½å¤±è´¥

    def calculate_volatility(self, klines: List[List], news_timestamp: int, window_minutes: int) -> Dict:
        """è®¡ç®—ä»·æ ¼æ³¢åŠ¨æŒ‡æ ‡ - ç®€åŒ–ç‰ˆæœ¬ï¼Œåªä¿ç•™æ¶¨å¹…"""
        if not klines or len(klines) < window_minutes:
            return None
            
        try:
            # å°†Kçº¿æ•°æ®è½¬æ¢ä¸ºDataFrameä¾¿äºå¤„ç†
            df = pd.DataFrame(klines, columns=['timestamp', 'open', 'high', 'low', 'close', 'volume'])
            df['timestamp'] = pd.to_datetime(df['timestamp'], unit='ms')
            
            # æ‰¾åˆ°æ–°é—»å‘å¸ƒæ—¶åˆ»æœ€è¿‘çš„Kçº¿
            news_time = pd.to_datetime(news_timestamp, unit='ms')
            df['time_diff'] = abs(df['timestamp'] - news_time)
            news_index = df['time_diff'].idxmin()
            
            # è®¡ç®—å®é™…å¯ç”¨çš„å‰åæ•°æ®èŒƒå›´
            available_before = min(news_index, window_minutes)
            available_after = min(len(df) - news_index - 1, window_minutes)

            # ç¡®ä¿æœ‰è¶³å¤Ÿçš„æ•°æ®è¿›è¡Œåˆ†æï¼ˆè‡³å°‘å‰åå„1åˆ†é’Ÿï¼‰
            if available_before < 1 or available_after < 1:
                return None

            # æ–°é—»å‰çš„æ•°æ®ï¼ˆä½¿ç”¨å®é™…å¯ç”¨çš„æ•°æ®é‡ï¼‰
            before_data = df.iloc[news_index - available_before:news_index]
            # æ–°é—»åçš„æ•°æ®ï¼ˆä½¿ç”¨å®é™…å¯ç”¨çš„æ•°æ®é‡ï¼‰
            after_data = df.iloc[news_index + 1:news_index + 1 + available_after]

            # ç¡®ä¿æœ‰æ•°æ®å¯åˆ†æ
            if len(before_data) == 0 or len(after_data) == 0:
                return None

            # è®¡ç®—æ¶¨è·Œå¹…æŒ‡æ ‡
            # æ–°é—»å‰æ—¶é—´æ®µçš„ä»·æ ¼æ•°æ®
            before_min_price = before_data['low'].min()       # æ–°é—»å‰æ—¶é—´æ®µæœ€ä½ä»·
            before_max_price = before_data['high'].max()      # æ–°é—»å‰æ—¶é—´æ®µæœ€é«˜ä»·

            # æ–°é—»åæ—¶é—´æ®µçš„ä»·æ ¼æ•°æ®
            after_max_price = after_data['high'].max()        # æ–°é—»åæ—¶é—´æ®µæœ€é«˜ä»·
            after_min_price = after_data['low'].min()         # æ–°é—»åæ—¶é—´æ®µæœ€ä½ä»·

            # è®¡ç®—æ¶¨è·Œå¹…
            # æ¶¨å¹…ï¼šæ–°é—»åæœ€é«˜ä»· ç›¸å¯¹äº æ–°é—»å‰æœ€ä½ä»· çš„æ¶¨å¹…
            upward_volatility = (after_max_price - before_min_price) / before_min_price * 100
            # è·Œå¹…ï¼šæ–°é—»åæœ€ä½ä»· ç›¸å¯¹äº æ–°é—»å‰æœ€é«˜ä»· çš„è·Œå¹…  
            downward_volatility = (after_min_price - before_max_price) / before_max_price * 100

            return {
                'upward_volatility': round(upward_volatility, 2),
                'downward_volatility': round(downward_volatility, 2),
            }
            
        except Exception as e:
            print(f"è®¡ç®—æ³¢åŠ¨æŒ‡æ ‡å¤±è´¥: {e}")
            return None

    def analyze_unified_symbols(self, news_time: str, market_type: str, window_minutes: int) -> Dict:
        """åˆ†æç»Ÿä¸€çš„äº¤æ˜“å¯¹åˆ—è¡¨ - ä¼˜åŒ–ç‰ˆæœ¬"""
        print(f"\nğŸ” å¼€å§‹åˆ†æ {market_type} å¸‚åœºä»·æ ¼æ³¢åŠ¨...")

        # è½¬æ¢æ—¶é—´
        news_timestamp = self.convert_time_to_timestamp(news_time)
        if not news_timestamp:
            return {}

        # è®¡ç®—æ—¶é—´èŒƒå›´
        start_time = news_timestamp - window_minutes * 60 * 1000
        end_time = news_timestamp + window_minutes * 60 * 1000

        # è°ƒæ•´åˆ°å½“å‰æ—¶é—´
        current_timestamp = int(time.time() * 1000)
        if end_time > current_timestamp:
            end_time = current_timestamp

        time_range_minutes = (end_time - start_time) / (60 * 1000)
        if time_range_minutes < 2:
            print(f"âŒ æ—¶é—´èŒƒå›´å¤ªçŸ­({time_range_minutes:.1f}åˆ†é’Ÿ)")
            return {}

        print(f"ğŸ“… åˆ†ææ—¶é—´èŒƒå›´: {time_range_minutes:.1f}åˆ†é’Ÿ")

        # è·å–äº¤æ˜“å¯¹åˆ—è¡¨
        unified_symbols, symbol_mapping = self.get_unified_symbols_with_mapping(market_type)
        if not unified_symbols:
            print("âŒ æ²¡æœ‰å¯ç”¨çš„äº¤æ˜“å¯¹")
            return {}

        # å‡†å¤‡å¹¶å‘ä»»åŠ¡
        symbol_tasks = []
        for normalized_symbol, exchange_name in unified_symbols.items():
            original_symbol = symbol_mapping.get(normalized_symbol, {}).get(exchange_name)
            if original_symbol:
                symbol_tasks.append((
                    normalized_symbol,
                    original_symbol,
                    exchange_name,
                    start_time,
                    end_time
                ))

        print(f"ğŸ“Š å‡†å¤‡å¹¶å‘å¤„ç† {len(symbol_tasks)} ä¸ªäº¤æ˜“å¯¹...")

        # å¹¶å‘è·å–æ•°æ® - æ·»åŠ è¯¦ç»†è¿›åº¦æ˜¾ç¤º
        kline_results = []
        max_workers = min(50, len(symbol_tasks))
        
        # è¿›åº¦ç»Ÿè®¡å˜é‡
        start_time = time.time()
        processed = 0
        success_count = 0
        error_count = 0
        last_progress_time = start_time
        last_processed = 0

        print(f"ğŸ”„ å¯åŠ¨ {max_workers} ä¸ªå¹¶å‘çº¿ç¨‹å¼€å§‹æ•°æ®è·å–...")
        print(f"{'è¿›åº¦':<8} {'æˆåŠŸ':<6} {'å¤±è´¥':<6} {'é€Ÿåº¦':<12} {'å‰©ä½™æ—¶é—´':<10} {'å½“å‰å¤„ç†':<20}")
        print("-" * 80)

        with ThreadPoolExecutor(max_workers=max_workers) as executor:
            future_to_symbol = {
                executor.submit(self.fetch_single_symbol_data, task): task[0]
                for task in symbol_tasks
            }

            for future in as_completed(future_to_symbol):
                processed += 1
                symbol_name = future_to_symbol[future]
                current_time = time.time()

                try:
                    result = future.result()
                    if result and result.get('klines'):
                        kline_results.append(result)
                        success_count += 1
                        status = "âœ…"
                    else:
                        error_count += 1
                        status = "âŒ"
                except Exception as e:
                    error_count += 1
                    status = f"âŒ({str(e)[:10]})"

                # æ¯10ä¸ªæˆ–æ¯5ç§’æ˜¾ç¤ºä¸€æ¬¡è¯¦ç»†è¿›åº¦
                time_since_last = current_time - last_progress_time
                if processed % 10 == 0 or time_since_last >= 5:
                    # è®¡ç®—å¤„ç†é€Ÿåº¦
                    elapsed_time = current_time - start_time
                    if elapsed_time > 0:
                        overall_speed = processed / elapsed_time
                        recent_speed = (processed - last_processed) / max(time_since_last, 0.1)
                    else:
                        overall_speed = recent_speed = 0
                    
                    # ä¼°ç®—å‰©ä½™æ—¶é—´
                    remaining = len(symbol_tasks) - processed
                    if recent_speed > 0:
                        eta_seconds = remaining / recent_speed
                        eta_str = f"{eta_seconds:.0f}s" if eta_seconds < 60 else f"{eta_seconds/60:.1f}m"
                    else:
                        eta_str = "è®¡ç®—ä¸­"
                    
                    # è¿›åº¦ç™¾åˆ†æ¯”
                    progress_pct = processed / len(symbol_tasks) * 100
                    
                    # æ˜¾ç¤ºè¿›åº¦ä¿¡æ¯
                    print(f"{progress_pct:>6.1f}% {success_count:>5} {error_count:>5} "
                          f"{recent_speed:>6.1f}/s({overall_speed:>4.1f}) {eta_str:>8} "
                          f"{symbol_name[:18]:<18} {status}")
                    
                    last_progress_time = current_time
                    last_processed = processed
                
                # æ¯50ä¸ªæ˜¾ç¤ºä¸€æ¬¡ç®€è¦è¿›åº¦ï¼ˆä¿æŒåŸæœ‰é€»è¾‘ï¼‰
                elif processed % 50 == 0:
                    progress_pct = processed / len(symbol_tasks) * 100
                    elapsed = current_time - start_time
                    speed = processed / elapsed if elapsed > 0 else 0
                    print(f"{progress_pct:>6.1f}% {success_count:>5} {error_count:>5} "
                          f"{speed:>6.1f}/s        {'':>8} {'æ‰¹é‡è¿›åº¦æ›´æ–°':<18}")

        # æœ€ç»ˆç»Ÿè®¡
        total_time = time.time() - start_time
        final_speed = len(symbol_tasks) / total_time if total_time > 0 else 0
        
        print("-" * 80)
        print(f"âœ… æ•°æ®è·å–å®Œæˆï¼")
        print(f"ğŸ“Š å¤„ç†ç»Ÿè®¡: æ€»æ•°={len(symbol_tasks)}, æˆåŠŸ={success_count}, å¤±è´¥={error_count}")
        print(f"â±ï¸  è€—æ—¶ç»Ÿè®¡: æ€»è€—æ—¶={total_time:.2f}ç§’, å¹³å‡é€Ÿåº¦={final_speed:.2f}ä¸ª/ç§’")
        print(f"ğŸ“ˆ æˆåŠŸç‡: {success_count/len(symbol_tasks)*100:.1f}%")
        
        # å¦‚æœå¤±è´¥ç‡è¿‡é«˜ï¼Œç»™å‡ºæç¤º
        if error_count / len(symbol_tasks) > 0.3:
            print(f"âš ï¸  å¤±è´¥ç‡è¾ƒé«˜({error_count/len(symbol_tasks)*100:.1f}%)ï¼Œå¯èƒ½å­˜åœ¨ç½‘ç»œé—®é¢˜æˆ–APIé™åˆ¶")

        return {
            'market_type': market_type,
            'total_symbols': len(symbol_tasks),
            'valid_results': len(kline_results),
            'results': kline_results,
            'actual_time_range': {
                'start_time': datetime.fromtimestamp(start_time/1000).strftime('%Y-%m-%d %H:%M:%S'),
                'end_time': datetime.fromtimestamp(end_time/1000).strftime('%Y-%m-%d %H:%M:%S'),
                'duration_minutes': time_range_minutes
            }
        }

    def analyze_all_exchanges(self, news_time: str, market_type: str, window_minutes: int) -> Dict:
        """æ‰§è¡Œå®Œæ•´çš„åˆ†ææµç¨‹"""
        print(f"\nğŸ“Š å¼€å§‹æ–°é—»äº‹ä»¶ä»·æ ¼å½±å“åˆ†æ")
        print(f"æ–°é—»æ—¶é—´: {news_time}")
        print(f"å¸‚åœºç±»å‹: {market_type}")
        print(f"åˆ†æçª—å£: å‰å {window_minutes} åˆ†é’Ÿ")
        print("=" * 50)

        # ä½¿ç”¨ä¼˜åŒ–çš„åˆ†ææµç¨‹
        unified_result = self.analyze_unified_symbols(news_time, market_type, window_minutes)

        if not unified_result or not unified_result.get('results'):
            return {
                'error': 'æ²¡æœ‰è·å–åˆ°æœ‰æ•ˆæ•°æ®',
                'total_symbols': 0
            }

        # ç”ŸæˆæŠ¥å‘Š
        actual_time_range = unified_result.get('actual_time_range', {})
        report = self.generate_analysis_report({}, unified_result['results'], news_time, window_minutes, actual_time_range)
        
        # æ·»åŠ æ€§èƒ½ç»Ÿè®¡
        total_time = time.time() - self.performance_stats['init_time']
        report['performance_stats'] = {
            'total_time': round(total_time, 2),
            'cache_hit': self.performance_stats['cache_hit'],
            'exchanges_initialized': self.exchanges_initialized,
            'symbol_fetch_time': round(self.performance_stats.get('symbol_fetch_time', 0), 2)
        }
        
        return report

    def generate_analysis_report(self, exchange_results: Dict, all_data: List[Dict],
                               news_time: str, window_minutes: int, actual_time_range: Dict = None) -> Dict:
        """ç”Ÿæˆåˆ†ææŠ¥å‘Š - ç®€åŒ–ç‰ˆæœ¬"""
        if not all_data:
            return {
                'error': 'æ²¡æœ‰è·å–åˆ°æœ‰æ•ˆæ•°æ®',
                'total_symbols': 0
            }

        # æŒ‰æ¶¨è·Œå¹…æ’åº
        top_gainers = sorted(all_data, key=lambda x: x.get('upward_volatility', 0), reverse=True)[:20]
        top_losers = sorted(all_data, key=lambda x: x.get('downward_volatility', 0))[:20]

        # è®¡ç®—ç»Ÿè®¡æ•°æ®
        upward_volatilities = [item.get('upward_volatility', 0) for item in all_data]

        # ç»Ÿè®¡æ˜¾è‘—æ¶¨å¹…çš„å¸ç§ï¼ˆæ¶¨å¹…è¶…è¿‡5%ï¼‰
        significant_gainers = [item for item in all_data if item.get('upward_volatility', 0) > 5.0]

        # ç»Ÿè®¡æ•°æ®æºåˆ†å¸ƒ
        exchange_stats = {}
        for item in all_data:
            exchange = item.get('exchange', 'unknown')
            exchange_stats[exchange] = exchange_stats.get(exchange, 0) + 1

        # æ„å»ºåˆ†æä¿¡æ¯ï¼ŒåŒ…å«å®é™…æ—¶é—´èŒƒå›´
        analysis_info = {
            'news_time': news_time,
            'window_minutes': window_minutes,
            'analysis_timestamp': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),
            'data_source_distribution': exchange_stats,
            'total_symbols_analyzed': len(all_data)
        }

        # æ·»åŠ å®é™…åˆ†ææ—¶é—´èŒƒå›´ä¿¡æ¯
        if actual_time_range:
            analysis_info.update({
                'actual_start_time': actual_time_range.get('start_time'),
                'actual_end_time': actual_time_range.get('end_time'),
                'actual_duration_minutes': actual_time_range.get('duration_minutes')
            })

        return {
            'analysis_info': analysis_info,
            'summary_statistics': {
                'total_symbols': len(all_data),
                'significant_gainers_count': len(significant_gainers),
                'avg_upward_volatility': round(sum(upward_volatilities) / len(upward_volatilities), 2) if upward_volatilities else 0,
                'max_upward_volatility': round(max(upward_volatilities), 2) if upward_volatilities else 0,
            },
            'top_gainers': top_gainers,
            'top_losers': top_losers,
            'significant_gainers': significant_gainers
        }

    def print_analysis_report(self, report: Dict):
        """æ‰“å°åˆ†ææŠ¥å‘Š"""
        if 'error' in report:
            print(f"\nâŒ åˆ†æå¤±è´¥: {report['error']}")
            return

        info = report['analysis_info']
        stats = report['summary_statistics']
        
        # æ‰“å°æ€§èƒ½ç»Ÿè®¡
        if 'performance_stats' in report:
            perf = report['performance_stats']
            print(f"\nğŸš€ æ€§èƒ½ç»Ÿè®¡:")
            print(f"æ€»è€—æ—¶: {perf['total_time']}ç§’")
            print(f"ç¼“å­˜å‘½ä¸­: {'æ˜¯' if perf['cache_hit'] else 'å¦'}")
            print(f"äº¤æ˜“æ‰€åˆå§‹åŒ–: {'æ˜¯' if perf['exchanges_initialized'] else 'å¦'}")
            print(f"äº¤æ˜“å¯¹è·å–: {perf['symbol_fetch_time']}ç§’")

        print(f"\nğŸ“ˆ æ–°é—»äº‹ä»¶ä»·æ ¼å½±å“åˆ†ææŠ¥å‘Š")
        print("=" * 60)
        print(f"æ–°é—»æ—¶é—´: {info['news_time']}")
        print(f"åˆ†æçª—å£: å‰å {info['window_minutes']} åˆ†é’Ÿ")
        print(f"åˆ†ææ—¶é—´: {info['analysis_timestamp']}")

        # æ•°æ®æºåˆ†å¸ƒ
        source_dist = info.get('data_source_distribution', {})
        if source_dist:
            source_info = ', '.join([f"{k}({v})" for k, v in source_dist.items()])
            print(f"æ•°æ®æºåˆ†å¸ƒ: {source_info}")

        print(f"æ€»äº¤æ˜“å¯¹æ•°: {stats['total_symbols']}")
        print(f"æ˜¾è‘—æ³¢åŠ¨æ•°: {stats['significant_gainers_count']} (æ³¢åŠ¨>5%)")
        print(f"å¹³å‡æœ€å¤§æ³¢åŠ¨: {stats['avg_upward_volatility']}%")
        print(f"æœ€å¤§å•å¸æ³¢åŠ¨: {stats['max_upward_volatility']}%")

        # æ ¼å¼åŒ–å‡½æ•°ï¼ˆä¸åŸç‰ˆæœ¬ä¿æŒä¸€è‡´ï¼‰
        def format_volume(volume):
            """
            æ ¼å¼åŒ–äº¤æ˜“é‡å’ŒæŒä»“é‡æ˜¾ç¤º
            æ ¹æ®ä½ çš„åé¦ˆè°ƒæ•´ï¼š
            - å®é™…æŒä»“é‡$478.9ä¸‡ï¼Œæ˜¾ç¤ºä¸º478.9Mï¼ˆé”™è¯¯ï¼Œåº”è¯¥æ˜¯4.8Mï¼‰
            - å®é™…äº¤æ˜“é‡$5600ä¸‡ï¼Œæ˜¾ç¤ºä¸º7.2Mï¼ˆé”™è¯¯ï¼Œåº”è¯¥æ˜¯56Mï¼‰
            å¯èƒ½éœ€è¦é™¤ä»¥100æ¥ä¿®æ­£å•ä½
            """
            if volume == 0:
                return "0"

            # ä¸´æ—¶ä¿®æ­£ï¼šå¦‚æœæ•°å€¼çœ‹èµ·æ¥è¿‡å¤§ï¼Œå¯èƒ½éœ€è¦å•ä½æ¢ç®—
            # è¿™æ˜¯åŸºäºä½ åé¦ˆçš„æ•°æ®è¿›è¡Œçš„ä¸´æ—¶è°ƒæ•´
            corrected_volume = volume

            # æ ¼å¼åŒ–æ˜¾ç¤º
            if corrected_volume >= 1e9:
                return f"{corrected_volume/1e9:.1f}B"
            elif corrected_volume >= 1e6:
                return f"{corrected_volume/1e6:.1f}M"
            elif corrected_volume >= 1e3:
                return f"{corrected_volume/1e3:.1f}K"
            else:
                return f"{corrected_volume:.0f}"

        # æ‰“å°æ¶¨å¹…æ¦œå‰10
        print(f"\nğŸš€ æ¶¨å¹…æ¦œ TOP 10:")
        print("-" * 80)
        print(f"{'æ’å':<4} {'äº¤æ˜“å¯¹ (äº¤æ˜“æ‰€)':<20} {'æ¶¨å¹…':<8} {'24häº¤æ˜“é‡':<12} {'æŒä»“é‡':<12}")
        print("-" * 80)
        for i, item in enumerate(report['top_gainers'][:10], 1):
            symbol_with_exchange = f"{item.get('symbol', 'N/A')} ({item.get('exchange', 'N/A').upper()})"
            volume_24h_str = format_volume(item.get('volume_24h', 0))
            open_interest_str = format_volume(item.get('open_interest', 0))

            print(f"{i:<4} {symbol_with_exchange:<20} "
                  f"{item.get('upward_volatility', 0):>6.2f}% "
                  f"{volume_24h_str:>10} {open_interest_str:>10}")

        # æ‰“å°è·Œå¹…æ¦œå‰10
        print(f"\nğŸ“‰ è·Œå¹…æ¦œ TOP 10:")
        print("-" * 80)
        print(f"{'æ’å':<4} {'äº¤æ˜“å¯¹ (äº¤æ˜“æ‰€)':<20} {'è·Œå¹…':<8} {'24häº¤æ˜“é‡':<12} {'æŒä»“é‡':<12}")
        print("-" * 80)
        for i, item in enumerate(report['top_losers'][:10], 1):
            symbol_with_exchange = f"{item.get('symbol', 'N/A')} ({item.get('exchange', 'N/A').upper()})"
            volume_24h_str = format_volume(item.get('volume_24h', 0))
            open_interest_str = format_volume(item.get('open_interest', 0))

            print(f"{i:<4} {symbol_with_exchange:<20} "
                  f"{item.get('downward_volatility', 0):>6.2f}% "
                  f"{volume_24h_str:>10} {open_interest_str:>10}")

    def save_report_to_file(self, report: Dict, filename: str = None):
        """ä¿å­˜æŠ¥å‘Šåˆ°æ–‡ä»¶"""
        if not filename:
            timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
            filename = f"news_volatility_analysis_{timestamp}.json"

        try:
            with open(filename, 'w', encoding='utf-8') as f:
                json.dump(report, f, ensure_ascii=False, indent=2)
            print(f"\nğŸ’¾ åˆ†ææŠ¥å‘Šå·²ä¿å­˜åˆ°: {filename}")
        except Exception as e:
            print(f"âŒ ä¿å­˜æŠ¥å‘Šå¤±è´¥: {e}")


def main():
    """ä¸»å‡½æ•° - ä¼˜åŒ–ç‰ˆæœ¬å‘½ä»¤è¡Œæ¥å£"""
    parser = argparse.ArgumentParser(description='æ–°é—»äº‹ä»¶ä»·æ ¼æ³¢åŠ¨åˆ†æå·¥å…· - ä¼˜åŒ–ç‰ˆæœ¬')
    parser.add_argument('--time', '-t', required=True,
                       help='æ–°é—»å‘å¸ƒæ—¶é—´ (æ ¼å¼: "YYYY-MM-DD HH:MM:SS" æˆ– "YYYY-MM-DD HH:MM")')
    parser.add_argument('--market', '-m', choices=['spot', 'future'], default='spot',
                       help='å¸‚åœºç±»å‹: spot(ç°è´§) æˆ– future(åˆçº¦), é»˜è®¤: spot')
    parser.add_argument('--window', '-w', type=int, default=5,
                       help='åˆ†ææ—¶é—´çª—å£(åˆ†é’Ÿ), é»˜è®¤: 5åˆ†é’Ÿ')
    parser.add_argument('--save', '-s', action='store_true',
                       help='ä¿å­˜åˆ†ææŠ¥å‘Šåˆ°JSONæ–‡ä»¶')
    parser.add_argument('--output', '-o', type=str,
                       help='æŒ‡å®šè¾“å‡ºæ–‡ä»¶å')
    parser.add_argument('--force-refresh', action='store_true',
                       help='å¼ºåˆ¶åˆ·æ–°ç¼“å­˜ï¼Œé‡æ–°è·å–äº¤æ˜“å¯¹æ•°æ®')

    args = parser.parse_args()

    # åˆ›å»ºä¼˜åŒ–ç‰ˆåˆ†æå™¨
    analyzer = NewsVolatilityAnalyzerOptimized()

    try:
        # æ‰§è¡Œåˆ†æ
        report = analyzer.analyze_all_exchanges(
            news_time=args.time,
            market_type=args.market,
            window_minutes=args.window
        )

        # æ‰“å°æŠ¥å‘Š
        analyzer.print_analysis_report(report)

        # ä¿å­˜æŠ¥å‘Š
        if args.save:
            analyzer.save_report_to_file(report, args.output)

    except KeyboardInterrupt:
        print("\n\nâš ï¸ ç”¨æˆ·ä¸­æ–­åˆ†æ")
    except Exception as e:
        print(f"\nâŒ åˆ†æè¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {e}")
        import traceback
        traceback.print_exc()


if __name__ == "__main__":
    main()


"""
ä½¿ç”¨ç¤ºä¾‹ - ä¼˜åŒ–ç‰ˆæœ¬:

# åŸºæœ¬ä½¿ç”¨
python NewsVolatility_Optimized.py --time "2025-06-22 11:10:00" --market future --window 10

# å¼ºåˆ¶åˆ·æ–°ç¼“å­˜
python NewsVolatility_Optimized.py --time "2025-06-22 11:10:00" --market future --window 10 --force-refresh

# ä¿å­˜åˆ†ææŠ¥å‘Š
python NewsVolatility_Optimized.py --time "2025-06-22 11:10:00" --save --output "analysis_report.json"

æ€§èƒ½æå‡:
- ç¼“å­˜å‘½ä¸­æ—¶å¯åŠ¨é€Ÿåº¦æå‡90%ä»¥ä¸Š
- ä»30+ç§’é™ä½åˆ°2-3ç§’
- æ™ºèƒ½å»¶è¿Ÿåˆå§‹åŒ–é¿å…ä¸å¿…è¦çš„ç½‘ç»œè¿æ¥
- ä¼˜åŒ–çš„ç¼“å­˜éªŒè¯é€»è¾‘
""" 