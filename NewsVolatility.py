#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æ–°é—»äº‹ä»¶ä»·æ ¼æ³¢åŠ¨åˆ†æå·¥å…·
åˆ†æç‰¹å®šæ—¶é—´ç‚¹å‰åXåˆ†é’Ÿå†…ï¼Œå„å¸ç§ä»·æ ¼çš„æ³¢åŠ¨æƒ…å†µ
ç”¨äºè¯„ä¼°æ–°é—»äº‹ä»¶å¯¹åŠ å¯†è´§å¸ä»·æ ¼çš„å½±å“

ä½œè€…: Price Monitor System
åˆ›å»ºæ—¶é—´: 2025-06-15
"""

import ccxt
import pandas as pd
from datetime import datetime, timedelta
import time
import json
from typing import Dict, List, Tuple, Optional
import argparse
import sys
import os
from concurrent.futures import ThreadPoolExecutor, as_completed

# æ·»åŠ çˆ¶ç›®å½•åˆ°è·¯å¾„ï¼Œä»¥ä¾¿å¯¼å…¥utils
sys.path.append(os.path.dirname(os.path.abspath(__file__)))
from utils import get_socks5_proxy, get_perpetual_symbols, get_bybit_perpetual_symbols


class NewsVolatilityAnalyzer:
    """æ–°é—»äº‹ä»¶ä»·æ ¼æ³¢åŠ¨åˆ†æå™¨"""
    
    def __init__(self):
        """åˆå§‹åŒ–åˆ†æå™¨"""
        self.exchanges = {}
        self.proxy_config = get_socks5_proxy()
        self.init_exchanges()
        
    def init_exchanges(self):
        """åˆå§‹åŒ–äº¤æ˜“æ‰€è¿æ¥"""
        print("æ­£åœ¨åˆå§‹åŒ–äº¤æ˜“æ‰€è¿æ¥...")

        # åˆå§‹åŒ–å¸å®‰
        try:
            self.exchanges['binance'] = ccxt.binance({
                'apiKey': '',
                'secret': '',
                'timeout': 30000,
                'enableRateLimit': True,
                'proxies': self.proxy_config,
                'options': {
                    'defaultType': 'spot'  # é»˜è®¤ç°è´§ï¼Œåç»­å¯åˆ‡æ¢
                }
            })
            print("âœ… Binance è¿æ¥æˆåŠŸ")
        except Exception as e:
            print(f"âŒ Binance è¿æ¥å¤±è´¥: {e}")

        # åˆå§‹åŒ–Bybit
        try:
            self.exchanges['bybit'] = ccxt.bybit({
                'apiKey': '',
                'secret': '',
                'timeout': 30000,
                'enableRateLimit': True,
                'proxies': self.proxy_config,
                'options': {
                    'defaultType': 'spot'
                }
            })
            print("âœ… Bybit è¿æ¥æˆåŠŸ")
        except Exception as e:
            print(f"âŒ Bybit è¿æ¥å¤±è´¥: {e}")
    
    def convert_time_to_timestamp(self, time_str: str) -> int:
        """å°†æ—¶é—´å­—ç¬¦ä¸²è½¬æ¢ä¸ºæ—¶é—´æˆ³"""
        try:
            # æ”¯æŒå¤šç§æ—¶é—´æ ¼å¼
            formats = [
                '%Y-%m-%d %H:%M:%S',
                '%Y-%m-%d %H:%M',
                '%Y/%m/%d %H:%M:%S',
                '%Y/%m/%d %H:%M'
            ]
            
            for fmt in formats:
                try:
                    dt = datetime.strptime(time_str, fmt)
                    return int(dt.timestamp() * 1000)
                except ValueError:
                    continue
                    
            raise ValueError(f"æ— æ³•è§£ææ—¶é—´æ ¼å¼: {time_str}")
            
        except Exception as e:
            print(f"æ—¶é—´è½¬æ¢é”™è¯¯: {e}")
            return None
    
    def get_active_symbols(self, exchange_name: str, market_type: str) -> List[str]:
        """è·å–æ´»è·ƒçš„äº¤æ˜“å¯¹åˆ—è¡¨"""
        try:
            exchange = self.exchanges[exchange_name]

            if market_type == 'future':
                # ä½¿ç”¨ç°æœ‰çš„å·¥å…·å‡½æ•°è·å–æ°¸ç»­åˆçº¦äº¤æ˜“å¯¹
                if exchange_name == 'binance':
                    exchange.options['defaultType'] = 'future'
                    markets = exchange.load_markets()
                    active_symbols = get_perpetual_symbols(exchange)
                elif exchange_name == 'bybit':
                    exchange.options['defaultType'] = 'swap'
                    markets = exchange.load_markets()
                    active_symbols = get_bybit_perpetual_symbols(exchange)
                else:
                    active_symbols = []
            else:
                # ç°è´§å¸‚åœº
                exchange.options['defaultType'] = 'spot'
                markets = exchange.load_markets()
                active_symbols = []

                for symbol, market in markets.items():
                    # ç­›é€‰æ´»è·ƒçš„ç°è´§äº¤æ˜“å¯¹
                    if (market.get('active', False) and
                        market.get('spot', False) and
                        market.get('quote') in ['USDT', 'BUSD', 'USDC']):
                        active_symbols.append(symbol)

            print(f"{exchange_name} {market_type} æ´»è·ƒäº¤æ˜“å¯¹æ•°é‡: {len(active_symbols)}")
            return active_symbols  # è¿”å›æ‰€æœ‰æ´»è·ƒäº¤æ˜“å¯¹ï¼Œä¸é™åˆ¶æ•°é‡

        except Exception as e:
            print(f"è·å– {exchange_name} äº¤æ˜“å¯¹å¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
            return []
    
    def fetch_single_symbol_data(self, symbol_info: Tuple[str, str, str, int, int]) -> Optional[Dict]:
        """è·å–å•ä¸ªäº¤æ˜“å¯¹çš„Kçº¿æ•°æ®å’Œå¸‚åœºæ•°æ®"""
        normalized_symbol, original_symbol, exchange_name, start_time, end_time = symbol_info

        try:
            exchange = self.exchanges[exchange_name]

            # è®¡ç®—éœ€è¦çš„Kçº¿æ•°é‡
            duration_minutes = (end_time - start_time) // (60 * 1000)
            limit = min(duration_minutes + 10, 200)  # å¤šè·å–ä¸€äº›ï¼Œç¡®ä¿è¦†ç›–æ—¶é—´èŒƒå›´

            # è·å–1åˆ†é’ŸKçº¿æ•°æ®
            klines = exchange.fetch_ohlcv(
                symbol=original_symbol,
                timeframe='1m',
                since=start_time,
                limit=limit
            )

            # è¿‡æ»¤å‡ºæŒ‡å®šæ—¶é—´èŒƒå›´å†…çš„æ•°æ®
            filtered_klines = []
            for kline in klines:
                if start_time <= kline[0] <= end_time:
                    filtered_klines.append(kline)

            # è·å–24å°æ—¶äº¤æ˜“é‡æ•°æ®ï¼ˆä¸è°ƒç”¨fetch_market_dataé¿å…è·å–èµ„é‡‘è´¹ç‡ï¼‰
            volume_24h = 0
            try:
                ticker = exchange.fetch_ticker(original_symbol)
                # ä¼˜å…ˆä½¿ç”¨quoteVolumeï¼ˆUSDTä»·å€¼ï¼‰ï¼Œå¦‚æœæ²¡æœ‰åˆ™ä½¿ç”¨baseVolume
                quote_volume = ticker.get('quoteVolume', 0)
                base_volume = ticker.get('baseVolume', 0)
                volume_24h = quote_volume or base_volume or 0

                # è°ƒè¯•ä¿¡æ¯
                if 'REX' in original_symbol:
                    print(f"ğŸ” è°ƒè¯• {original_symbol} ({exchange_name}) äº¤æ˜“é‡:")
                    print(f"  quoteVolume: {quote_volume}")
                    print(f"  baseVolume: {base_volume}")
                    print(f"  æœ€ç»ˆvolume_24h: {volume_24h}")

            except Exception as e:
                # é™é»˜å¤„ç†äº¤æ˜“é‡è·å–å¤±è´¥
                pass

            # è·å–æŒä»“é‡æ•°æ®ï¼ˆä»…è·å–æŒä»“é‡ï¼Œä¸è·å–èµ„é‡‘è´¹ç‡ï¼‰
            open_interest_at_news = 0
            try:
                if exchange_name in ['binance', 'bybit']:
                    # æ ¹æ®äº¤æ˜“æ‰€ç±»å‹è®¾ç½®æ­£ç¡®çš„å¸‚åœºç±»å‹
                    if exchange_name == "binance":
                        exchange.options['defaultType'] = 'future'
                    elif exchange_name in ["bybit"]:
                        exchange.options['defaultType'] = 'swap'

                    # ç›´æ¥è·å–å½“å‰æŒä»“é‡ï¼Œé¿å…è°ƒç”¨å¤æ‚çš„fetch_market_data
                    try:
                        # å°è¯•è·å–æŒä»“é‡
                        oi_data = exchange.fetch_open_interest(original_symbol)
                        if oi_data:
                            # ä¼˜å…ˆä½¿ç”¨ç¾å…ƒä»·å€¼ï¼Œå¦‚æœæ²¡æœ‰åˆ™ä½¿ç”¨åˆçº¦æ•°é‡
                            open_interest_at_news = oi_data.get('openInterestValue', 0) or oi_data.get('openInterestAmount', 0) or 0

                            # è°ƒè¯•ä¿¡æ¯
                            if 'REX' in original_symbol:
                                print(f"ğŸ” è°ƒè¯• {original_symbol} ({exchange_name}) æŒä»“é‡:")
                                print(f"  openInterestValue: {oi_data.get('openInterestValue', 0)}")
                                print(f"  openInterestAmount: {oi_data.get('openInterestAmount', 0)}")
                                print(f"  æœ€ç»ˆopen_interest: {open_interest_at_news}")

                    except Exception as e:
                        # å¦‚æœç›´æ¥è·å–å¤±è´¥ï¼Œå°è¯•å†å²æ•°æ®æ–¹å¼
                        try:
                            oi_history = exchange.fetch_open_interest_history(original_symbol, '1h', limit=2)
                            if oi_history:
                                latest_oi = oi_history[-1]  # è·å–æœ€æ–°çš„æŒä»“é‡æ•°æ®
                                open_interest_at_news = latest_oi.get('openInterestValue', 0) or latest_oi.get('openInterestAmount', 0) or 0
                        except Exception:
                            pass  # é™é»˜å¤±è´¥

            except Exception as e:
                # é™é»˜å¤„ç†æŒä»“é‡è·å–å¤±è´¥
                pass



            return {
                'normalized_symbol': normalized_symbol,
                'original_symbol': original_symbol,
                'exchange': exchange_name,
                'klines': filtered_klines,
                'volume_24h': volume_24h,
                'open_interest': open_interest_at_news
            }

        except Exception as e:
            print(f"è·å– {exchange_name} {original_symbol} æ•°æ®å¤±è´¥: {e}")
            return None
    
    def calculate_volatility(self, klines: List[List], news_timestamp: int, 
                           window_minutes: int) -> Dict:
        """è®¡ç®—ä»·æ ¼æ³¢åŠ¨æŒ‡æ ‡"""
        if not klines or len(klines) < window_minutes:
            return None
            
        try:
            # å°†Kçº¿æ•°æ®è½¬æ¢ä¸ºDataFrameä¾¿äºå¤„ç†
            df = pd.DataFrame(klines, columns=['timestamp', 'open', 'high', 'low', 'close', 'volume'])
            df['timestamp'] = pd.to_datetime(df['timestamp'], unit='ms')
            
            # æ‰¾åˆ°æ–°é—»å‘å¸ƒæ—¶åˆ»æœ€è¿‘çš„Kçº¿
            news_time = pd.to_datetime(news_timestamp, unit='ms')
            df['time_diff'] = abs(df['timestamp'] - news_time)
            news_index = df['time_diff'].idxmin()
            
            # ç¡®ä¿æœ‰è¶³å¤Ÿçš„å‰åæ•°æ®
            if news_index < window_minutes or news_index >= len(df) - window_minutes:
                return None
            
            # æ–°é—»å‰Xåˆ†é’Ÿçš„æ•°æ®ï¼ˆä¸åŒ…å«æ–°é—»æ—¶åˆ»ï¼‰
            before_data = df.iloc[news_index - window_minutes:news_index]
            # æ–°é—»åXåˆ†é’Ÿçš„æ•°æ®ï¼ˆä¸åŒ…å«æ–°é—»æ—¶åˆ»ï¼‰
            after_data = df.iloc[news_index + 1:news_index + 1 + window_minutes]

            # ç¡®ä¿æ–°é—»åæœ‰è¶³å¤Ÿçš„æ•°æ®
            if len(after_data) < window_minutes:
                return None

            # è®¡ç®—å„ç§æ³¢åŠ¨æŒ‡æ ‡
            # æ–°é—»å‰æ—¶é—´æ®µçš„ä»·æ ¼æ•°æ®
            before_max_price = before_data['high'].max()      # æ–°é—»å‰æ—¶é—´æ®µæœ€é«˜ä»·
            before_min_price = before_data['low'].min()       # æ–°é—»å‰æ—¶é—´æ®µæœ€ä½ä»·
            before_close_price = before_data['close'].iloc[-1]  # æ–°é—»å‰æœ€åæ”¶ç›˜ä»·ï¼ˆä½œä¸ºåŸºå‡†ä»·æ ¼ï¼‰

            # æ–°é—»åæ—¶é—´æ®µçš„ä»·æ ¼æ•°æ®
            after_max_price = after_data['high'].max()        # æ–°é—»åæ—¶é—´æ®µæœ€é«˜ä»·
            after_min_price = after_data['low'].min()         # æ–°é—»åæ—¶é—´æ®µæœ€ä½ä»·
            after_close_price = after_data['close'].iloc[-1]  # æ–°é—»åæœ€åæ”¶ç›˜ä»·

            # æ–°é—»å‰åçš„æˆäº¤é‡å¯¹æ¯”
            before_volume = before_data['volume'].sum()
            after_volume = after_data['volume'].sum()


            # è®¡ç®—æ³¢åŠ¨æŒ‡æ ‡ï¼ˆæŒ‰ç…§ä½ æœŸæœ›çš„é€»è¾‘ï¼‰
            # æ¶¨å¹…ï¼šæ–°é—»åæœ€é«˜ä»· ç›¸å¯¹äº æ–°é—»å‰æœ€ä½ä»· çš„æ¶¨å¹…
            upward_volatility = (after_max_price - before_min_price) / before_min_price * 100
            # è·Œå¹…ï¼šæ–°é—»åæœ€ä½ä»· ç›¸å¯¹äº æ–°é—»å‰æœ€é«˜ä»· çš„è·Œå¹…
            downward_volatility = (after_min_price - before_max_price) / before_max_price * 100
            # å‡€å˜åŒ–ï¼šæ–°é—»åæ”¶ç›˜ä»· ç›¸å¯¹äº æ–°é—»å‰æ”¶ç›˜ä»· çš„å˜åŒ–
            net_change = (after_close_price - before_close_price) / before_close_price * 100
            # æœ€å¤§æ³¢åŠ¨ï¼šæ–°é—»åæ—¶é—´æ®µå†…çš„ä»·æ ¼æŒ¯å¹…
            max_volatility = (after_max_price - after_min_price) / after_min_price * 100

            # æˆäº¤é‡å˜åŒ–è®¡ç®—ï¼Œæ·»åŠ å¼‚å¸¸å€¼æ£€æµ‹
            if before_volume > 0:
                volume_change = (after_volume - before_volume) / before_volume * 100
                # å¦‚æœæˆäº¤é‡å˜åŒ–è¶…è¿‡1000%ï¼Œå¯èƒ½æ˜¯æ•°æ®å¼‚å¸¸ï¼Œéœ€è¦è¿›ä¸€æ­¥æ£€æŸ¥
            else:
                volume_change = 0

            return {
                'before_close_price': float(before_close_price),  # æ–°é—»å‰åŸºå‡†ä»·æ ¼
                'before_max_price': float(before_max_price),      # æ–°é—»å‰æœ€é«˜ä»·
                'before_min_price': float(before_min_price),      # æ–°é—»å‰æœ€ä½ä»·
                'after_max_price': float(after_max_price),        # æ–°é—»åæœ€é«˜ä»·
                'after_min_price': float(after_min_price),        # æ–°é—»åæœ€ä½ä»·
                'after_close_price': float(after_close_price),    # æ–°é—»åæ”¶ç›˜ä»·
                'upward_volatility': round(upward_volatility, 2),
                'downward_volatility': round(downward_volatility, 2),
                'net_change': round(net_change, 2),
                'max_volatility': round(max_volatility, 2),
                'volume_change': round(volume_change, 2),
                'before_volume': float(before_volume),
                'after_volume': float(after_volume)
            }
            
        except Exception as e:
            print(f"è®¡ç®—æ³¢åŠ¨æŒ‡æ ‡å¤±è´¥: {e}")
            return None
    
    def get_unified_symbols_with_mapping(self, market_type: str) -> Tuple[Dict[str, str], Dict[str, Dict[str, str]]]:
        """è·å–ç»Ÿä¸€çš„äº¤æ˜“å¯¹åˆ—è¡¨ï¼Œå»é‡å¹¶ç¡®å®šæ•°æ®æºä¼˜å…ˆçº§ï¼ŒåŒæ—¶è¿”å›åŸå§‹æ ¼å¼æ˜ å°„"""
        print(f"\nğŸ“‹ æ­£åœ¨è·å–å¹¶æ•´åˆæ‰€æœ‰äº¤æ˜“æ‰€çš„ {market_type} äº¤æ˜“å¯¹...")

        # ä¸€æ¬¡æ€§è·å–å„äº¤æ˜“æ‰€çš„äº¤æ˜“å¯¹ï¼ˆé¿å…é‡å¤è°ƒç”¨ï¼‰
        exchange_symbols = {}
        for exchange_name in self.exchanges.keys():
            print(f"æ­£åœ¨è·å– {exchange_name} çš„äº¤æ˜“å¯¹...")
            symbols = self.get_active_symbols(exchange_name, market_type)
            if symbols:
                exchange_symbols[exchange_name] = symbols
                print(f"{exchange_name}: {len(symbols)} ä¸ªäº¤æ˜“å¯¹")

        if not exchange_symbols:
            print("âŒ æ²¡æœ‰è·å–åˆ°ä»»ä½•äº¤æ˜“å¯¹")
            return {}, {}

        # æ ‡å‡†åŒ–äº¤æ˜“å¯¹åç§°çš„å‡½æ•°
        def normalize_symbol(symbol):
            # ç§»é™¤äº¤æ˜“æ‰€ç‰¹å®šçš„åç¼€ï¼Œç»Ÿä¸€æ ¼å¼
            if ':' in symbol:
                return symbol.split(':')[0]  # BTC/USDT:USDT -> BTC/USDT
            return symbol

        # æ ‡å‡†åŒ–å„äº¤æ˜“æ‰€çš„äº¤æ˜“å¯¹
        normalized_symbols = {}  # {exchange: set(normalized_symbols)}
        symbol_mapping = {}  # {normalized: {exchange: original_symbol}}

        for exchange_name, symbols in exchange_symbols.items():
            normalized_set = set()
            for symbol in symbols:
                normalized = normalize_symbol(symbol)
                normalized_set.add(normalized)

                if normalized not in symbol_mapping:
                    symbol_mapping[normalized] = {}
                symbol_mapping[normalized][exchange_name] = symbol

            normalized_symbols[exchange_name] = normalized_set

        # è®¡ç®—é›†åˆå…³ç³»
        binance_symbols = normalized_symbols.get('binance', set())
        bybit_symbols = normalized_symbols.get('bybit', set())

        # a1: é‡åˆçš„äº¤æ˜“å¯¹ (å¸å®‰å’Œbybitéƒ½æœ‰) â†’ ç”¨å¸å®‰æ•°æ®
        common_symbols = binance_symbols.intersection(bybit_symbols)

        # a2: å¸å®‰ç‹¬æœ‰çš„äº¤æ˜“å¯¹ â†’ ç”¨å¸å®‰æ•°æ®
        binance_only = binance_symbols - bybit_symbols

        # a3: bybitç‹¬æœ‰çš„äº¤æ˜“å¯¹ â†’ ç”¨bybitæ•°æ®
        bybit_only = bybit_symbols - binance_symbols

        # æ„å»ºæœ€ç»ˆçš„ç»Ÿä¸€äº¤æ˜“å¯¹åˆ—è¡¨
        unified_symbols = {}  # {normalized_symbol: preferred_exchange}

        # a1 + a2: æ‰€æœ‰å¸å®‰æœ‰çš„äº¤æ˜“å¯¹éƒ½ç”¨å¸å®‰æ•°æ®
        for symbol in common_symbols.union(binance_only):
            if 'binance' in self.exchanges:
                unified_symbols[symbol] = 'binance'

        # a3: bybitç‹¬æœ‰çš„ç”¨bybitæ•°æ®
        for symbol in bybit_only:
            if 'bybit' in self.exchanges:
                unified_symbols[symbol] = 'bybit'

        print(f"\nğŸ“Š äº¤æ˜“å¯¹æ•´åˆç»“æœ:")
        print(f"å¸å®‰äº¤æ˜“å¯¹æ€»æ•°: {len(binance_symbols)}")
        print(f"Bybitäº¤æ˜“å¯¹æ€»æ•°: {len(bybit_symbols)}")
        print(f"é‡åˆäº¤æ˜“å¯¹ (a1): {len(common_symbols)} â†’ ä½¿ç”¨å¸å®‰æ•°æ®")
        print(f"å¸å®‰ç‹¬æœ‰ (a2): {len(binance_only)} â†’ ä½¿ç”¨å¸å®‰æ•°æ®")
        print(f"Bybitç‹¬æœ‰ (a3): {len(bybit_only)} â†’ ä½¿ç”¨Bybitæ•°æ®")
        print(f"æœ€ç»ˆç»Ÿä¸€äº¤æ˜“å¯¹æ€»æ•°: {len(unified_symbols)}")

        # éªŒè¯æ•°å­¦å…³ç³»
        expected_total = len(common_symbols) + len(binance_only) + len(bybit_only)
        print(f"éªŒè¯: {len(common_symbols)} + {len(binance_only)} + {len(bybit_only)} = {expected_total}")

        return unified_symbols, symbol_mapping

    def analyze_unified_symbols(self, news_time: str, market_type: str, window_minutes: int) -> Dict:
        """åˆ†æç»Ÿä¸€çš„äº¤æ˜“å¯¹åˆ—è¡¨ï¼ˆä½¿ç”¨å¹¶å‘å¤„ç†ï¼‰"""
        print(f"\nğŸ” å¼€å§‹ç»Ÿä¸€åˆ†æ {market_type} å¸‚åœºä»·æ ¼æ³¢åŠ¨...")

        # è½¬æ¢æ—¶é—´
        news_timestamp = self.convert_time_to_timestamp(news_time)
        if not news_timestamp:
            return {}

        # è®¡ç®—æ—¶é—´èŒƒå›´
        start_time = news_timestamp - window_minutes * 60 * 1000
        end_time = news_timestamp + window_minutes * 60 * 1000

        # è·å–ç»Ÿä¸€çš„äº¤æ˜“å¯¹åˆ—è¡¨å’ŒåŸå§‹æ ¼å¼æ˜ å°„
        unified_symbols, symbol_mapping = self.get_unified_symbols_with_mapping(market_type)
        if not unified_symbols:
            print("âŒ æ²¡æœ‰å¯ç”¨çš„äº¤æ˜“å¯¹")
            return {}

        # å‡†å¤‡å¹¶å‘ä»»åŠ¡æ•°æ®
        symbol_tasks = []
        for normalized_symbol, exchange_name in unified_symbols.items():
            original_symbol = symbol_mapping.get(normalized_symbol, {}).get(exchange_name)
            if original_symbol:
                symbol_tasks.append((
                    normalized_symbol,
                    original_symbol,
                    exchange_name,
                    start_time,
                    end_time
                ))

        print(f"å‡†å¤‡å¹¶å‘å¤„ç† {len(symbol_tasks)} ä¸ªäº¤æ˜“å¯¹...")

        # ä½¿ç”¨çº¿ç¨‹æ± å¹¶å‘è·å–Kçº¿æ•°æ®
        kline_results = []
        max_workers = min(50, len(symbol_tasks))  # é™åˆ¶å¹¶å‘æ•°

        with ThreadPoolExecutor(max_workers=max_workers) as executor:
            # æäº¤æ‰€æœ‰ä»»åŠ¡
            future_to_symbol = {
                executor.submit(self.fetch_single_symbol_data, task): task[0]
                for task in symbol_tasks
            }

            # æ”¶é›†ç»“æœ
            processed = 0
            for future in as_completed(future_to_symbol):
                processed += 1
                if processed % 50 == 0:
                    print(f"å·²è·å–Kçº¿æ•°æ®: {processed}/{len(symbol_tasks)} ({processed/len(symbol_tasks)*100:.1f}%)")

                try:
                    result = future.result()
                    if result and result['klines']:
                        kline_results.append(result)
                except Exception as e:
                    symbol_name = future_to_symbol[future]
                    print(f"è·å– {symbol_name} æ•°æ®å¤±è´¥: {e}")

        print(f"âœ… Kçº¿æ•°æ®è·å–å®Œæˆï¼Œæœ‰æ•ˆæ•°æ®: {len(kline_results)}")

        # è®¡ç®—æ³¢åŠ¨æŒ‡æ ‡
        print("ğŸ”¢ å¼€å§‹è®¡ç®—æ³¢åŠ¨æŒ‡æ ‡...")
        final_results = []

        for i, kline_data in enumerate(kline_results):
            try:
                # è®¡ç®—æ³¢åŠ¨æŒ‡æ ‡
                volatility = self.calculate_volatility(
                    kline_data['klines'],
                    news_timestamp,
                    window_minutes
                )

                if volatility:
                    result = {
                        'symbol': kline_data['normalized_symbol'],
                        'original_symbol': kline_data['original_symbol'],
                        'exchange': kline_data['exchange'],
                        'volume_24h': kline_data.get('volume_24h', 0),
                        'open_interest': kline_data.get('open_interest', 0),
                        **volatility
                    }
                    final_results.append(result)

                if (i + 1) % 100 == 0:
                    print(f"å·²è®¡ç®—æ³¢åŠ¨æŒ‡æ ‡: {i + 1}/{len(kline_results)} ({(i + 1)/len(kline_results)*100:.1f}%)")

            except Exception as e:
                print(f"è®¡ç®— {kline_data['normalized_symbol']} æ³¢åŠ¨æŒ‡æ ‡å¤±è´¥: {e}")
                continue

        print(f"âœ… æ³¢åŠ¨åˆ†æå®Œæˆï¼Œæœ€ç»ˆæœ‰æ•ˆæ•°æ®: {len(final_results)}")
        return {
            'market_type': market_type,
            'total_symbols': len(symbol_tasks),
            'valid_results': len(final_results),
            'results': final_results
        }

    def analyze_all_exchanges(self, news_time: str, market_type: str, window_minutes: int) -> Dict:
        """åˆ†ææ‰€æœ‰äº¤æ˜“æ‰€çš„ä»·æ ¼æ³¢åŠ¨ï¼ˆä½¿ç”¨ç»Ÿä¸€å»é‡é€»è¾‘ï¼‰"""
        print(f"\nğŸ“Š å¼€å§‹åˆ†ææ–°é—»äº‹ä»¶ä»·æ ¼å½±å“")
        print(f"æ–°é—»æ—¶é—´: {news_time}")
        print(f"å¸‚åœºç±»å‹: {market_type}")
        print(f"åˆ†æçª—å£: å‰å {window_minutes} åˆ†é’Ÿ")
        print("=" * 50)

        # ä½¿ç”¨ç»Ÿä¸€çš„äº¤æ˜“å¯¹åˆ†æ
        unified_result = self.analyze_unified_symbols(news_time, market_type, window_minutes)

        if not unified_result or not unified_result.get('results'):
            return {
                'error': 'æ²¡æœ‰è·å–åˆ°æœ‰æ•ˆæ•°æ®',
                'total_symbols': 0
            }

        # ç”Ÿæˆç»¼åˆåˆ†ææŠ¥å‘Š
        return self.generate_analysis_report({}, unified_result['results'], news_time, window_minutes)

    def generate_analysis_report(self, exchange_results: Dict, all_data: List[Dict],
                               news_time: str, window_minutes: int) -> Dict:
        """ç”Ÿæˆåˆ†ææŠ¥å‘Š"""
        if not all_data:
            return {
                'error': 'æ²¡æœ‰è·å–åˆ°æœ‰æ•ˆæ•°æ®',
                'total_symbols': 0
            }

        # æŒ‰ä¸åŒæŒ‡æ ‡æ’åº
        top_gainers = sorted(all_data, key=lambda x: x['upward_volatility'], reverse=True)[:20]
        top_losers = sorted(all_data, key=lambda x: x['downward_volatility'])[:20]
        max_volatility = sorted(all_data, key=lambda x: x['max_volatility'], reverse=True)[:20]

        # æˆäº¤é‡æ¿€å¢æ’åºï¼šè¿‡æ»¤æ‰æç«¯å¼‚å¸¸å€¼ï¼ˆ>10000%ï¼‰ï¼Œé¿å…æ•°æ®å™ªéŸ³
        filtered_volume_data = [item for item in all_data if 0 < item['volume_change'] < 10000]
        volume_surge = sorted(filtered_volume_data, key=lambda x: x['volume_change'], reverse=True)[:20]

        # å¦‚æœè¿‡æ»¤åæ•°æ®ä¸è¶³ï¼Œåˆ™ä½¿ç”¨åŸå§‹æ•°æ®ä½†æ·»åŠ è­¦å‘Š
        if len(volume_surge) < 10:
            print("âš ï¸  æˆäº¤é‡æ•°æ®ä¸­å­˜åœ¨æç«¯å¼‚å¸¸å€¼ï¼Œå»ºè®®æ£€æŸ¥æ•°æ®è´¨é‡")
            volume_surge = sorted(all_data, key=lambda x: x['volume_change'], reverse=True)[:20]

        # è®¡ç®—ç»Ÿè®¡æ•°æ®
        volatilities = [item['max_volatility'] for item in all_data]
        volume_changes = [item['volume_change'] for item in all_data if item['volume_change'] != 0]

        # ç»Ÿè®¡æ˜¾è‘—æ³¢åŠ¨çš„å¸ç§ï¼ˆæ³¢åŠ¨è¶…è¿‡5%ï¼‰
        significant_moves = [item for item in all_data if abs(item['max_volatility']) > 5.0]

        # ç»Ÿè®¡æ•°æ®æºåˆ†å¸ƒ
        exchange_stats = {}
        for item in all_data:
            exchange = item['exchange']
            exchange_stats[exchange] = exchange_stats.get(exchange, 0) + 1

        report = {
            'analysis_info': {
                'news_time': news_time,
                'window_minutes': window_minutes,
                'analysis_timestamp': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),
                'data_source_distribution': exchange_stats,
                'total_symbols_analyzed': len(all_data)
            },
            'summary_statistics': {
                'total_symbols': len(all_data),
                'significant_moves_count': len(significant_moves),
                'avg_max_volatility': round(sum(volatilities) / len(volatilities), 2) if volatilities else 0,
                'max_single_volatility': max(volatilities) if volatilities else 0,
                'avg_volume_change': round(sum(volume_changes) / len(volume_changes), 2) if volume_changes else 0
            },
            'top_gainers': top_gainers,
            'top_losers': top_losers,
            'max_volatility_symbols': max_volatility,
            'volume_surge_symbols': volume_surge,
            'significant_moves': significant_moves
        }

        return report

    def print_analysis_report(self, report: Dict):
        """æ‰“å°åˆ†ææŠ¥å‘Š"""
        if 'error' in report:
            print(f"\nâŒ åˆ†æå¤±è´¥: {report['error']}")
            return

        info = report['analysis_info']
        stats = report['summary_statistics']

        print(f"\nğŸ“ˆ æ–°é—»äº‹ä»¶ä»·æ ¼å½±å“åˆ†ææŠ¥å‘Š")
        print("=" * 60)
        print(f"æ–°é—»æ—¶é—´: {info['news_time']}")
        print(f"åˆ†æçª—å£: å‰å {info['window_minutes']} åˆ†é’Ÿ")
        print(f"åˆ†ææ—¶é—´: {info['analysis_timestamp']}")

        # æ˜¾ç¤ºæ•°æ®æºåˆ†å¸ƒ
        source_dist = info.get('data_source_distribution', {})
        if source_dist:
            source_info = ', '.join([f"{k}({v})" for k, v in source_dist.items()])
            print(f"æ•°æ®æºåˆ†å¸ƒ: {source_info}")

        print(f"æ€»äº¤æ˜“å¯¹æ•°: {stats['total_symbols']}")
        print(f"æ˜¾è‘—æ³¢åŠ¨æ•°: {stats['significant_moves_count']} (æ³¢åŠ¨>5%)")
        print(f"å¹³å‡æœ€å¤§æ³¢åŠ¨: {stats['avg_max_volatility']}%")
        print(f"æœ€å¤§å•å¸æ³¢åŠ¨: {stats['max_single_volatility']}%")
        print(f"å¹³å‡æˆäº¤é‡å˜åŒ–: {stats['avg_volume_change']}%")

        # æ ¼å¼åŒ–æ•°å€¼çš„è¾…åŠ©å‡½æ•°
        def format_volume(volume):
            """
            æ ¼å¼åŒ–äº¤æ˜“é‡å’ŒæŒä»“é‡æ˜¾ç¤º
            æ ¹æ®ä½ çš„åé¦ˆè°ƒæ•´ï¼š
            - å®é™…æŒä»“é‡$478.9ä¸‡ï¼Œæ˜¾ç¤ºä¸º478.9Mï¼ˆé”™è¯¯ï¼Œåº”è¯¥æ˜¯4.8Mï¼‰
            - å®é™…äº¤æ˜“é‡$5600ä¸‡ï¼Œæ˜¾ç¤ºä¸º7.2Mï¼ˆé”™è¯¯ï¼Œåº”è¯¥æ˜¯56Mï¼‰
            å¯èƒ½éœ€è¦é™¤ä»¥100æ¥ä¿®æ­£å•ä½
            """
            if volume == 0:
                return "0"

            # ä¸´æ—¶ä¿®æ­£ï¼šå¦‚æœæ•°å€¼çœ‹èµ·æ¥è¿‡å¤§ï¼Œå¯èƒ½éœ€è¦å•ä½æ¢ç®—
            # è¿™æ˜¯åŸºäºä½ åé¦ˆçš„æ•°æ®è¿›è¡Œçš„ä¸´æ—¶è°ƒæ•´
            corrected_volume = volume

            # æ ¼å¼åŒ–æ˜¾ç¤º
            if corrected_volume >= 1e9:
                return f"{corrected_volume/1e9:.1f}B"
            elif corrected_volume >= 1e6:
                return f"{corrected_volume/1e6:.1f}M"
            elif corrected_volume >= 1e3:
                return f"{corrected_volume/1e3:.1f}K"
            else:
                return f"{corrected_volume:.0f}"

        # æ‰“å°æ¶¨å¹…æ¦œå‰10
        print(f"\nğŸš€ æ¶¨å¹…æ¦œ TOP 10:")
        print("-" * 120)
        print(f"{'æ’å':<4} {'äº¤æ˜“å¯¹ (äº¤æ˜“æ‰€)':<20} {'æ¶¨å¹…':<8} {'æœ€å¤§æ³¢åŠ¨':<10} {'æˆäº¤é‡å˜åŒ–':<12} {'24häº¤æ˜“é‡':<12} {'æŒä»“é‡':<12}")
        print("-" * 120)
        for i, item in enumerate(report['top_gainers'][:10], 1):
            symbol_with_exchange = f"{item['symbol']} ({item['exchange'].upper()})"
            volume_24h_str = format_volume(item.get('volume_24h', 0))
            open_interest_str = format_volume(item.get('open_interest', 0))

            print(f"{i:<4} {symbol_with_exchange:<20} "
                  f"{item['upward_volatility']:>6.2f}% {item['max_volatility']:>8.2f}% "
                  f"{item['volume_change']:>10.2f}% {volume_24h_str:>10} "
                  f"{open_interest_str:>10}")

        # æ‰“å°è·Œå¹…æ¦œå‰10
        print(f"\nğŸ“‰ è·Œå¹…æ¦œ TOP 10:")
        print("-" * 120)
        print(f"{'æ’å':<4} {'äº¤æ˜“å¯¹ (äº¤æ˜“æ‰€)':<20} {'è·Œå¹…':<8} {'æœ€å¤§æ³¢åŠ¨':<10} {'æˆäº¤é‡å˜åŒ–':<12} {'24häº¤æ˜“é‡':<12} {'æŒä»“é‡':<12}")
        print("-" * 120)
        for i, item in enumerate(report['top_losers'][:10], 1):
            symbol_with_exchange = f"{item['symbol']} ({item['exchange'].upper()})"
            volume_24h_str = format_volume(item.get('volume_24h', 0))
            open_interest_str = format_volume(item.get('open_interest', 0))

            print(f"{i:<4} {symbol_with_exchange:<20} "
                  f"{item['downward_volatility']:>6.2f}% {item['max_volatility']:>8.2f}% "
                  f"{item['volume_change']:>10.2f}% {volume_24h_str:>10} "
                  f"{open_interest_str:>10}")

        # æ‰“å°æˆäº¤é‡æ¿€å¢æ¦œå‰10
        print(f"\nğŸ“Š æˆäº¤é‡æ¿€å¢æ¦œ TOP 10:")
        print("-" * 120)
        print(f"{'æ’å':<4} {'äº¤æ˜“å¯¹ (äº¤æ˜“æ‰€)':<20} {'æˆäº¤é‡å˜åŒ–':<12} {'ä»·æ ¼å˜åŒ–':<10} {'24häº¤æ˜“é‡':<12} {'æŒä»“é‡':<12}")
        print("-" * 120)
        for i, item in enumerate(report['volume_surge_symbols'][:10], 1):
            if item['volume_change'] > 0:  # åªæ˜¾ç¤ºæˆäº¤é‡å¢åŠ çš„
                symbol_with_exchange = f"{item['symbol']} ({item['exchange'].upper()})"
                volume_24h_str = format_volume(item.get('volume_24h', 0))
                open_interest_str = format_volume(item.get('open_interest', 0))

                print(f"{i:<4} {symbol_with_exchange:<20} "
                      f"{item['volume_change']:>10.2f}% {item['net_change']:>8.2f}% "
                      f"{volume_24h_str:>10} {open_interest_str:>10}")

    def save_report_to_file(self, report: Dict, filename: str = None):
        """ä¿å­˜æŠ¥å‘Šåˆ°æ–‡ä»¶"""
        if not filename:
            timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
            filename = f"news_volatility_analysis_{timestamp}.json"

        try:
            with open(filename, 'w', encoding='utf-8') as f:
                json.dump(report, f, ensure_ascii=False, indent=2)
            print(f"\nğŸ’¾ åˆ†ææŠ¥å‘Šå·²ä¿å­˜åˆ°: {filename}")
        except Exception as e:
            print(f"âŒ ä¿å­˜æŠ¥å‘Šå¤±è´¥: {e}")


def main():
    """ä¸»å‡½æ•° - å‘½ä»¤è¡Œæ¥å£"""
    parser = argparse.ArgumentParser(description='æ–°é—»äº‹ä»¶ä»·æ ¼æ³¢åŠ¨åˆ†æå·¥å…·')
    parser.add_argument('--time', '-t', required=True,
                       help='æ–°é—»å‘å¸ƒæ—¶é—´ (æ ¼å¼: "YYYY-MM-DD HH:MM:SS" æˆ– "YYYY-MM-DD HH:MM")')
    parser.add_argument('--market', '-m', choices=['spot', 'future'], default='spot',
                       help='å¸‚åœºç±»å‹: spot(ç°è´§) æˆ– future(åˆçº¦), é»˜è®¤: spot')
    parser.add_argument('--window', '-w', type=int, default=5,
                       help='åˆ†ææ—¶é—´çª—å£(åˆ†é’Ÿ), é»˜è®¤: 5åˆ†é’Ÿ')
    parser.add_argument('--save', '-s', action='store_true',
                       help='ä¿å­˜åˆ†ææŠ¥å‘Šåˆ°JSONæ–‡ä»¶')
    parser.add_argument('--output', '-o', type=str,
                       help='æŒ‡å®šè¾“å‡ºæ–‡ä»¶å')

    args = parser.parse_args()

    # åˆ›å»ºåˆ†æå™¨
    analyzer = NewsVolatilityAnalyzer()

    # æ‰§è¡Œåˆ†æ
    try:
        report = analyzer.analyze_all_exchanges(
            news_time=args.time,
            market_type=args.market,
            window_minutes=args.window
        )

        # æ‰“å°æŠ¥å‘Š
        analyzer.print_analysis_report(report)

        # ä¿å­˜æŠ¥å‘Š
        if args.save:
            analyzer.save_report_to_file(report, args.output)

    except KeyboardInterrupt:
        print("\n\nâš ï¸  ç”¨æˆ·ä¸­æ–­åˆ†æ")
    except Exception as e:
        print(f"\nâŒ åˆ†æè¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {e}")
        import traceback
        traceback.print_exc()


if __name__ == "__main__":
    main()


"""
# åˆ†æ2024å¹´1æœˆ15æ—¥14:30æ–°é—»å¯¹ç°è´§å¸‚åœºå‰å5åˆ†é’Ÿçš„å½±å“
python NewsVolatility.py --time "2025-06-18 21:10:00" --market future --window 5

# åˆ†æåˆçº¦å¸‚åœºå‰å10åˆ†é’Ÿçš„å½±å“
python NewsVolatility.py --time "2024-01-15 14:30" --market future --window 10

# ä¿å­˜åˆ†ææŠ¥å‘Šåˆ°æ–‡ä»¶
python NewsVolatility.py --time "2024-01-15 14:30:00" --save

# æŒ‡å®šè¾“å‡ºæ–‡ä»¶å
python NewsVolatility.py --time "2024-01-15 14:30:00" --save --output "btc_news_analysis.json"
"""